# -*- coding: utf-8 -*-
"""HeartDiseasePredictionModel.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1VYb-Nqt5x4XEAR2Ls9__GmNBxqeWKZSw

1. GEREKLİ KÜTÜPHANELERİN İÇE AKTARILMASI
"""

# Veri okuma ve veri manipülasyonu için modüller
import pandas as pd
import numpy as np

# Görselleştirme için modüller
import seaborn as sns
import matplotlib.pyplot as plt

# Modelleme için scikit-learn modülleri
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.preprocessing import StandardScaler
from sklearn.neighbors import KNeighborsClassifier
from sklearn.neural_network import MLPClassifier
from sklearn.linear_model import LogisticRegression

# Değerlendirme metrikleri
from sklearn.metrics import (
    accuracy_score,
    classification_report,
    confusion_matrix
)

# Uyarı mesajlarını ekrana bastırmak için
import warnings
warnings.filterwarnings("ignore")

# Grafiklerin daha güzel görünmesi için
sns.set(style="whitegrid", font_scale=1.1)

# Rastgelelik içeren işlemler için seed ayarladık.
RANDOM_STATE = 42
np.random.seed(RANDOM_STATE)

"""2. VERİNİN OKUNMASI VE İLK İNCELEME"""

# heart.csv dosyasını okuyoruz ve genel istatistiklerini çıkartıyoruz.
df = pd.read_csv("heart.csv")

print("İlk 5 gözlem:")
display(df.head())

print("\nSon 5 gözlem:")
display(df.tail())

print("\nVeri setinin boyutu (satır, sütun):", df.shape)

print("\nVeri tipleri ve boş değer bilgisi:")
display(df.info())

print("\nSayısal değişkenlerin temel istatistiksel özeti:")
display(df.describe())

"""3. EKSİK DEĞER ANALİZİ"""

print("\nHer bir sütundaki eksik değer sayısı:")
missing_values = df.isnull().sum()
print(missing_values)

# Eğer eksik değer yoksa bunu da belirtmek güzel olur.
if missing_values.sum() == 0:
    print("\nVeri setinde eksik değer bulunmamaktadır.")
else:
    print("\nEksik değerler tespit edildi, uygun yöntemle doldurulmalıdır.")

"""4. HEDEF DEĞİŞKENİN (target) DAĞILIMI"""

# target: 1 -> kalp hastalığı var, 0 -> yok
plt.figure(figsize=(5, 4))
sns.countplot(x="target", data=df)
plt.title("Hedef Değişken (target) Dağılımı")
plt.xlabel("target (0: yok, 1: var)")
plt.ylabel("Gözlem Sayısı")
plt.show()

print("\ntarget sınıf oranları:")
print(df["target"].value_counts(normalize=True))

"""5. ÖZELLİKLERİN TEMEL GÖRSEL ANALİZİ (EDA)"""

# Örnek olarak birkaç önemli değişkenin dağılımını inceleyelim
numeric_cols = df.columns.drop("target")  # tüm bağımsız değişkenler

# Yaş dağılımı
plt.figure(figsize=(6, 4))
sns.histplot(df["age"], kde=True)
plt.title("Yaş Değişkeninin Dağılımı")
plt.xlabel("age")
plt.ylabel("Frekans")
plt.show()

# Yaşa göre hedef değişken
plt.figure(figsize=(6, 4))
sns.boxplot(x="target", y="age", data=df)
plt.title("Hedef Değişkene Göre Yaş Dağılımı")
plt.xlabel("target (0: yok, 1: var)")
plt.ylabel("age")
plt.show()

# Kolesterol dağılımı
if "chol" in df.columns:
    plt.figure(figsize=(6, 4))
    sns.histplot(df["chol"], kde=True)
    plt.title("Kolesterol (chol) Değişkeninin Dağılımı")
    plt.xlabel("chol")
    plt.ylabel("Frekans")
    plt.show()

"""6. KORELASYON MATRİSİ"""

# Korelasyon matrisi: sayısal değişkenler arasındaki ilişkiyi gösterir.
plt.figure(figsize=(12, 8))
sns.heatmap(df.corr(), annot=False, cmap="coolwarm")
plt.title("Korelasyon Matrisi")
plt.show()

"""7. ÖZELLİKLER VE HEDEFİN AYRILMASI"""

# Hedef değişken
y = df["target"]

# Bağımsız değişkenler
X = df.drop("target", axis=1)

print("\nBağımsız değişkenlerin ilk 5 satırı:")
display(X.head())

print("\nHedef değişkenin ilk 5 satırı:")
display(y.head())

"""8. VERİNİN ÖLÇEKLENMESİ (SCALING)"""

# Özellikle KNN ve MLP gibi mesafe/hız duyarlı algoritmalar için önemlidir.

scaler = StandardScaler()

# Tüm X değişkenlerine standartlaştırma uyguluyoruz
X_scaled = scaler.fit_transform(X)

print("\nÖlçeklendirilmiş verinin (X_scaled) örnek ilk 5 gözlemi:")
print(X_scaled[:5])

"""9. EĞİTİM - TEST AYRIMI"""

# Verinin bir kısmını model eğitimi, bir kısmını da performans ölçümü için ayırıyoruz.

X_train, X_test, y_train, y_test = train_test_split(
    X_scaled,
    y,
    test_size=0.2,         # %20 test, %80 eğitim
    random_state=RANDOM_STATE,
    stratify=y
)

print("\nEğitim ve test setlerinin boyutları:")
print("X_train:", X_train.shape)
print("X_test :", X_test.shape)
print("y_train:", y_train.shape)
print("y_test :", y_test.shape)

"""10. YARDIMCI FONKSİYON: MODEL EĞİTİM ve DEĞERLENDİRME"""

def train_and_evaluate(model, model_name, X_train, X_test, y_train, y_test):
    """
    Verilen modeli eğiten ve temel sınıflandırma performansını raporlayan yardımcı fonksiyon.

    Parametreler:
        model      : sklearn sınıflandırma modeli
        model_name : str, modelin ismi (örneğin 'KNN', 'MLP', 'LogReg')
        X_train    : eğitim özellikleri
        X_test     : test özellikleri
        y_train    : eğitim etiketleri
        y_test     : test etiketleri
    """
    print(f"\n==================== {model_name} ====================")

    # Modelin eğitilmesi
    model.fit(X_train, y_train)

    # Test verisi üzerinde tahmin
    y_pred = model.predict(X_test)

    # Temel doğruluk skoru
    acc = accuracy_score(y_test, y_pred)
    print(f"{model_name} Accuracy: {acc:.4f}")

    # Detaylı sınıflandırma raporu
    print("\nSınıflandırma Raporu:")
    print(classification_report(y_test, y_pred))

    # Karışıklık matrisi (Confusion Matrix)
    cm = confusion_matrix(y_test, y_pred)
    plt.figure(figsize=(4, 3))
    sns.heatmap(cm, annot=True, fmt="d", cmap="Blues")
    plt.title(f"{model_name} - Confusion Matrix")
    plt.xlabel("Tahmin Edilen")
    plt.ylabel("Gerçek")
    plt.show()

    return acc

"""11. FARKLI MODELLERİN KURULMASI"""

# Lojistik Regresyon (baseline, klasik doğrusal model)
log_reg = LogisticRegression(random_state=RANDOM_STATE, max_iter=500)

# K-En Yakın Komşu (KNN) modeli
# n_neighbors: bakılan komşu sayısı (deneme-yanılma ile iyileştirilebilir)
knn = KNeighborsClassifier(n_neighbors=5)

# MLP (Yapay Sinir Ağı) modeli
mlp = MLPClassifier(
    hidden_layer_sizes=(32, 16),
    activation="relu",
    max_iter=500,
    random_state=RANDOM_STATE
)

"""12. MODELLERİN EĞİTİLMESİ VE PERFORMANS KARŞILAŞTIRMASI"""

results = {}  # model adlarını ve doğruluk skorlarını saklamak için sözlük

# Lojistik Regresyon
acc_log_reg = train_and_evaluate(log_reg, "Lojistik Regresyon", X_train, X_test, y_train, y_test)
results["Lojistik Regresyon"] = acc_log_reg

# KNN
acc_knn = train_and_evaluate(knn, "KNN", X_train, X_test, y_train, y_test)
results["KNN"] = acc_knn

# MLP
acc_mlp = train_and_evaluate(mlp, "MLP (Yapay Sinir Ağı)", X_train, X_test, y_train, y_test)
results["MLP (Yapay Sinir Ağı]"] = acc_mlp

print("\nModel Doğruluk Skorları:")
for model_name, acc in results.items():
    print(f"{model_name}: {acc:.4f}")

"""13. MODELLERİN KARŞILAŞTIRMALI GRAFİĞİ"""

# Son olarak sonuçları bir DataFrame'e çevirip çubuk grafik çizelim
results_df = pd.DataFrame.from_dict(results, orient="index", columns=["Accuracy"])
results_df = results_df.sort_values(by="Accuracy", ascending=False)

plt.figure(figsize=(6, 4))
sns.barplot(x=results_df.index, y="Accuracy", data=results_df)
plt.ylim(0, 1)
plt.title("Modellere Göre Accuracy Karşılaştırması")
plt.ylabel("Accuracy")
plt.xticks(rotation=15)
plt.show()

print("\nEn iyi performansı gösteren model:")
print(results_df.head(1))